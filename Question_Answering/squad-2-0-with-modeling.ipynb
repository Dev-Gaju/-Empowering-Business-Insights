{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#training data\n# context=[]\n# queries =[]\n# answer =[]\n# for group in dataset_squad_v2['train']:\n#     context.append(group['context'])\n#     queries.append(group['question'])\n#     answer.append(group['answers'])\n    \n# train_text, train_queries, train_ansr = context, queries, answer","metadata":{"execution":{"iopub.status.busy":"2023-10-30T04:55:28.398047Z","iopub.execute_input":"2023-10-30T04:55:28.398400Z","iopub.status.idle":"2023-10-30T04:55:28.402877Z","shell.execute_reply.started":"2023-10-30T04:55:28.398371Z","shell.execute_reply":"2023-10-30T04:55:28.401828Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Downloaded Dataset from official Website\n\n- Take Json data\n- Extract question, Answer and Context\n- Add end_enswer position with Context and answer\n- Tokenize question and context together and create encodding\n- Add the position of answer start and end to the encoding\n- Create dataset with encodding part\n- import model and load encoding part with Dataloader and batch_size\n- Check devices and optimizer\n- train model from dataset like encodding part and extract conteext, question and start, end position\n- evaluation\n- Done","metadata":{}},{"cell_type":"code","source":"# https://github.com/alexaapo/BERT-based-pretrained-model-using-SQuAD-2.0-dataset/blob/main/Fine_Tuning_Bert.ipynb\n# https://gist.github.com/jamescalam/55daf50c8da9eb3a7c18de058bc139a3\n# https://huggingface.co/docs/transformers/tasks/question_answering","metadata":{"execution":{"iopub.status.busy":"2023-10-30T04:55:28.404365Z","iopub.execute_input":"2023-10-30T04:55:28.404637Z","iopub.status.idle":"2023-10-30T04:55:28.414348Z","shell.execute_reply.started":"2023-10-30T04:55:28.404614Z","shell.execute_reply":"2023-10-30T04:55:28.413542Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"if not os.path.exists('./data/benchmarks/squad'):\n    os.makedirs('./data/benchmarks/squad')","metadata":{"execution":{"iopub.status.busy":"2023-10-30T06:27:35.629154Z","iopub.execute_input":"2023-10-30T06:27:35.629541Z","iopub.status.idle":"2023-10-30T06:27:35.635468Z","shell.execute_reply.started":"2023-10-30T06:27:35.629490Z","shell.execute_reply":"2023-10-30T06:27:35.634556Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"import requests, os\nurl = 'https://rajpurkar.github.io/SQuAD-explorer/dataset/'\nres = requests.get(f'{url}train-v2.0.json')","metadata":{"execution":{"iopub.status.busy":"2023-10-30T06:27:43.304271Z","iopub.execute_input":"2023-10-30T06:27:43.304661Z","iopub.status.idle":"2023-10-30T06:27:43.706149Z","shell.execute_reply.started":"2023-10-30T06:27:43.304632Z","shell.execute_reply":"2023-10-30T06:27:43.705283Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"for file in ['train-v2.0.json', 'dev-v2.0.json']:\n    res = requests.get(f'{url}{file}')\n    # write to file\n    with open(f'./data/benchmarks/squad/{file}', 'wb') as f:\n        for chunk in res.iter_content(chunk_size=4):\n            f.write(chunk)","metadata":{"execution":{"iopub.status.busy":"2023-10-30T06:28:07.293148Z","iopub.execute_input":"2023-10-30T06:28:07.294220Z","iopub.status.idle":"2023-10-30T06:28:14.078257Z","shell.execute_reply.started":"2023-10-30T06:28:07.294176Z","shell.execute_reply":"2023-10-30T06:28:14.077434Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"import json\ndef read_squad(path):\n    with open(path, 'rb') as f:\n        squad_dict = json.load(f)\n#         print(squad_dict)\n\n    contexts = []\n    questions = []\n    answers = []\n    # iterate through all data in squad data\n    for group in squad_dict['data']:\n        for passage in group['paragraphs']:\n            context = passage['context']\n            for qa in passage['qas']:\n                question = qa['question']\n                if 'plausible_answers' in qa.keys():\n                    access = 'plausible_answers'\n                else:\n                    access = 'answers'\n                for answer in qa['answers']:\n                    # append data to lists\n                    contexts.append(context)\n                    questions.append(question)\n                    answers.append(answer)\n    # return formatted data lists\n    return contexts, questions, answers","metadata":{"execution":{"iopub.status.busy":"2023-10-30T04:59:53.946146Z","iopub.execute_input":"2023-10-30T04:59:53.946517Z","iopub.status.idle":"2023-10-30T04:59:53.956102Z","shell.execute_reply.started":"2023-10-30T04:59:53.946477Z","shell.execute_reply":"2023-10-30T04:59:53.954802Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train_contexts, train_questions, train_answers = read_squad('./data/benchmarks/squad/train-v2.0.json')\nval_contexts, val_questions, val_answers = read_squad('./data/benchmarks/squad/dev-v2.0.json')","metadata":{"execution":{"iopub.status.busy":"2023-10-30T06:29:12.691457Z","iopub.execute_input":"2023-10-30T06:29:12.692177Z","iopub.status.idle":"2023-10-30T06:29:15.467123Z","shell.execute_reply.started":"2023-10-30T06:29:12.692147Z","shell.execute_reply":"2023-10-30T06:29:15.465959Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"train_contexts[0],train_questions[0],train_answers[0]","metadata":{"execution":{"iopub.status.busy":"2023-10-30T04:59:57.684804Z","iopub.execute_input":"2023-10-30T04:59:57.685092Z","iopub.status.idle":"2023-10-30T04:59:57.691719Z","shell.execute_reply.started":"2023-10-30T04:59:57.685068Z","shell.execute_reply":"2023-10-30T04:59:57.690881Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"('Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".',\n 'When did Beyonce start becoming popular?',\n {'text': 'in the late 1990s', 'answer_start': 269})"},"metadata":{}}]},{"cell_type":"markdown","source":"---\n## Create the Answer_End Location","metadata":{}},{"cell_type":"code","source":"\ndef add_end_idx(answers, contexts):\n    # loop through each answer-context pair\n    for answer, context in zip(answers, contexts):\n        # gold_text refers to the answer we are expecting to find in context\n        gold_text = answer['text']\n        # we already know the start index\n        start_idx = answer['answer_start']\n        # and ideally this would be the end index...\n        end_idx = start_idx + len(gold_text)\n#         print(context[start_idx:end_idx])\n       \n\n        # ...however, sometimes squad answers are off by a character or two\n        if context[start_idx:end_idx] == gold_text:\n            # if the answer is not off :)\n            answer['answer_end'] = end_idx\n        else:\n            for n in [1, 2]:\n                if context[start_idx-n:end_idx-n] == gold_text:\n                    # this means the answer is off by 'n' tokens\n                    answer['answer_start'] = start_idx - n\n                    answer['answer_end'] = end_idx - n\nadd_end_idx(train_answers, train_contexts)\nadd_end_idx(val_answers, val_contexts)","metadata":{"execution":{"iopub.status.busy":"2023-10-30T04:59:59.455580Z","iopub.execute_input":"2023-10-30T04:59:59.455929Z","iopub.status.idle":"2023-10-30T04:59:59.547477Z","shell.execute_reply.started":"2023-10-30T04:59:59.455904Z","shell.execute_reply":"2023-10-30T04:59:59.546678Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"train_answers[0]","metadata":{"execution":{"iopub.status.busy":"2023-10-30T05:00:00.296462Z","iopub.execute_input":"2023-10-30T05:00:00.296953Z","iopub.status.idle":"2023-10-30T05:00:00.303233Z","shell.execute_reply.started":"2023-10-30T05:00:00.296914Z","shell.execute_reply":"2023-10-30T05:00:00.302329Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"{'text': 'in the late 1990s', 'answer_start': 269, 'answer_end': 286}"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DistilBertTokenizerFast\ntokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n\ntrain_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\nval_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-30T05:00:01.095786Z","iopub.execute_input":"2023-10-30T05:00:01.096475Z","iopub.status.idle":"2023-10-30T05:00:35.807779Z","shell.execute_reply.started":"2023-10-30T05:00:01.096442Z","shell.execute_reply":"2023-10-30T05:00:35.806775Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"train_encodings.keys()","metadata":{"execution":{"iopub.status.busy":"2023-10-30T05:00:45.090895Z","iopub.execute_input":"2023-10-30T05:00:45.091491Z","iopub.status.idle":"2023-10-30T05:00:45.097116Z","shell.execute_reply.started":"2023-10-30T05:00:45.091458Z","shell.execute_reply":"2023-10-30T05:00:45.096214Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"dict_keys(['input_ids', 'attention_mask'])"},"metadata":{}}]},{"cell_type":"code","source":"#check inputIds\n# train_encodings['input_ids'][0]\ntokenizer.decode(train_encodings['input_ids'][0])","metadata":{"execution":{"iopub.status.busy":"2023-10-30T05:00:47.519577Z","iopub.execute_input":"2023-10-30T05:00:47.519943Z","iopub.status.idle":"2023-10-30T05:00:47.533200Z","shell.execute_reply.started":"2023-10-30T05:00:47.519901Z","shell.execute_reply":"2023-10-30T05:00:47.532237Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"'[CLS] beyonce giselle knowles - carter ( / biːˈjɒnseɪ / bee - yon - say ) ( born september 4, 1981 ) is an american singer, songwriter, record producer and actress. born and raised in houston, texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of r & b girl - group destiny\\'s child. managed by her father, mathew knowles, the group became one of the world\\'s best - selling girl groups of all time. their hiatus saw the release of beyonce\\'s debut album, dangerously in love ( 2003 ), which established her as a solo artist worldwide, earned five grammy awards and featured the billboard hot 100 number - one singles \" crazy in love \" and \" baby boy \". [SEP] when did beyonce start becoming popular? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"},"metadata":{}}]},{"cell_type":"code","source":"#converting character to token we found for answer\ntrain_encodings.char_to_token(0, train_answers[0]['answer_start'])\ntrain_encodings.char_to_token(0, train_answers[0]['answer_end']-1)","metadata":{"execution":{"iopub.status.busy":"2023-10-30T05:00:51.244224Z","iopub.execute_input":"2023-10-30T05:00:51.244607Z","iopub.status.idle":"2023-10-30T05:00:51.251136Z","shell.execute_reply.started":"2023-10-30T05:00:51.244577Z","shell.execute_reply":"2023-10-30T05:00:51.250160Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"70"},"metadata":{}}]},{"cell_type":"markdown","source":"---\n## Add start and end syntax Vals to the Encoding dataset","metadata":{}},{"cell_type":"code","source":"def add_token_positions(encodings, answers):\n    # initialize lists to contain the token indices of answer start/end\n    start_positions = []\n    end_positions = []\n    for i in range(len(answers)):\n        # append start/end token position using char_to_token method\n        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end']))\n\n        # if start position is None, the answer passage has been truncated\n        if start_positions[-1] is None:\n            start_positions[-1] = tokenizer.model_max_length\n        # end position cannot be found, char_to_token found space, so shift one token forward\n        go_back = 1\n        while end_positions[-1] is None:\n            end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end']-go_back)\n            go_back +=1\n    # update our encodings object with the new token-based start/end positions\n    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n\n# apply function to our data\nadd_token_positions(train_encodings, train_answers)\nadd_token_positions(val_encodings, val_answers)","metadata":{"execution":{"iopub.status.busy":"2023-10-30T05:00:55.371098Z","iopub.execute_input":"2023-10-30T05:00:55.371983Z","iopub.status.idle":"2023-10-30T05:00:55.904917Z","shell.execute_reply.started":"2023-10-30T05:00:55.371950Z","shell.execute_reply":"2023-10-30T05:00:55.904038Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"val_encodings.keys()","metadata":{"execution":{"iopub.status.busy":"2023-10-30T05:00:57.488401Z","iopub.execute_input":"2023-10-30T05:00:57.489122Z","iopub.status.idle":"2023-10-30T05:00:57.494765Z","shell.execute_reply.started":"2023-10-30T05:00:57.489091Z","shell.execute_reply":"2023-10-30T05:00:57.493933Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"dict_keys(['input_ids', 'attention_mask', 'start_positions', 'end_positions'])"},"metadata":{}}]},{"cell_type":"code","source":"train_encodings['end_positions'][0]","metadata":{"execution":{"iopub.status.busy":"2023-10-30T04:56:19.607473Z","iopub.execute_input":"2023-10-30T04:56:19.608056Z","iopub.status.idle":"2023-10-30T04:56:19.616317Z","shell.execute_reply.started":"2023-10-30T04:56:19.608023Z","shell.execute_reply":"2023-10-30T04:56:19.615563Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"70"},"metadata":{}}]},{"cell_type":"code","source":"train_encodings.items()","metadata":{"execution":{"iopub.status.busy":"2023-10-30T04:56:19.617495Z","iopub.execute_input":"2023-10-30T04:56:19.618189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\nclass SquadDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings):\n        self.encodings = encodings\n\n    def __getitem__(self, idx):\n        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n\n    def __len__(self):\n        return len(self.encodings.input_ids)\n\ntrain_dataset = SquadDataset(train_encodings)\nval_dataset = SquadDataset(val_encodings)","metadata":{"execution":{"iopub.status.busy":"2023-10-30T05:01:01.267325Z","iopub.execute_input":"2023-10-30T05:01:01.268001Z","iopub.status.idle":"2023-10-30T05:01:03.505396Z","shell.execute_reply.started":"2023-10-30T05:01:01.267968Z","shell.execute_reply":"2023-10-30T05:01:03.504260Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"from transformers import BertForQuestionAnswering, BertTokenizer, TrainingArguments, Trainer, DistilBertForQuestionAnswering\n\nfrom transformers import DistilBertForQuestionAnswering\nmodel=DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased-distilled-squad')","metadata":{"execution":{"iopub.status.busy":"2023-10-30T05:08:10.427570Z","iopub.execute_input":"2023-10-30T05:08:10.428255Z","iopub.status.idle":"2023-10-30T05:08:12.286489Z","shell.execute_reply.started":"2023-10-30T05:08:10.428224Z","shell.execute_reply":"2023-10-30T05:08:12.285507Z"},"trusted":true},"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/451 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12f2e7ab51e348d08a270d31bccd966b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb87ac08081c448c8dfb4b5de6cae365"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import logging\nlogging.set_verbosity_error()\nlogging.set_verbosity_warning()","metadata":{"execution":{"iopub.status.busy":"2023-10-30T05:08:33.427306Z","iopub.execute_input":"2023-10-30T05:08:33.428216Z","iopub.status.idle":"2023-10-30T05:08:33.432062Z","shell.execute_reply.started":"2023-10-30T05:08:33.428177Z","shell.execute_reply":"2023-10-30T05:08:33.431148Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"from transformers import BertForQuestionAnswering\nfrom torch.utils.data import DataLoader\nfrom transformers import AdamW\nfrom tqdm import tqdm\n# model = DistilBertForQuestionAnswering.from_pretrained(\"bert-base-uncased\")\n# setup GPU/CPU\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n# move model over to detected device\nmodel.to(device)\n# activate training mode of model\nmodel.train()\n# initialize adam optimizer with weight decay (reduces chance of overfitting)\noptim = AdamW(model.parameters(), lr=5e-5)\n# initialize data loader for training data\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nloop = tqdm(train_loader, leave=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-30T05:10:09.148370Z","iopub.execute_input":"2023-10-30T05:10:09.148747Z","iopub.status.idle":"2023-10-30T05:10:09.166421Z","shell.execute_reply.started":"2023-10-30T05:10:09.148718Z","shell.execute_reply":"2023-10-30T05:10:09.165488Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stderr","text":"  0%|          | 0/5427 [00:00<?, ?it/s]","output_type":"stream"}]},{"cell_type":"code","source":"for epoch in range(1):\n    for batch in loop:\n        # initialize calculated gradients (from prev step)\n        optim.zero_grad()\n        # pull all the tensor batches required for training\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        start_positions = batch['start_positions'].to(device)\n        end_positions = batch['end_positions'].to(device)\n        # train model on batch and return outputs (incl. loss)\n        outputs = model(input_ids, attention_mask=attention_mask,\n                        start_positions=start_positions,\n                        end_positions=end_positions)\n        # extract loss\n        loss = outputs[0]\n        # calculate loss for every parameter that needs grad update\n        loss.backward()\n        # update parameters\n        optim.step()\n        # print relevant info to progress bar\n        loop.set_description(f'Epoch {epoch}')\n        loop.set_postfix(loss=loss.item())","metadata":{"execution":{"iopub.status.busy":"2023-10-30T05:10:11.465857Z","iopub.execute_input":"2023-10-30T05:10:11.466199Z","iopub.status.idle":"2023-10-30T05:49:16.869103Z","shell.execute_reply.started":"2023-10-30T05:10:11.466174Z","shell.execute_reply":"2023-10-30T05:49:16.868207Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stderr","text":"Epoch 0: 100%|██████████| 5427/5427 [39:07<00:00,  2.31it/s, loss=0.762]\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nmodel_path='./custom-distilbert/'\nos.makedirs(model_path,exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-30T06:21:05.337724Z","iopub.execute_input":"2023-10-30T06:21:05.338518Z","iopub.status.idle":"2023-10-30T06:21:05.342732Z","shell.execute_reply.started":"2023-10-30T06:21:05.338478Z","shell.execute_reply":"2023-10-30T06:21:05.341824Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"#HuggingFace standard formate\nmodel.save_pretrained(model_path)\ntokenizer.save_pretrained(model_path)","metadata":{"execution":{"iopub.status.busy":"2023-10-30T06:21:25.219412Z","iopub.execute_input":"2023-10-30T06:21:25.220107Z","iopub.status.idle":"2023-10-30T06:21:25.585656Z","shell.execute_reply.started":"2023-10-30T06:21:25.220077Z","shell.execute_reply":"2023-10-30T06:21:25.584703Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"('./custom-distilbert/tokenizer_config.json',\n './custom-distilbert/special_tokens_map.json',\n './custom-distilbert/vocab.txt',\n './custom-distilbert/added_tokens.json',\n './custom-distilbert/tokenizer.json')"},"metadata":{}}]},{"cell_type":"markdown","source":"## EVAL The Model","metadata":{}},{"cell_type":"code","source":"# switch model out of training mode\nmodel.eval()\n\n#val_sampler = SequentialSampler(val_dataset)\nval_loader = DataLoader(val_dataset, batch_size=16)\n\nacc = []\n\n# initialize loop for progress bar\nloop = tqdm(val_loader)\n# loop through batches\nfor batch in loop:\n    # we don't need to calculate gradients as we're not training\n    with torch.no_grad():\n        # pull batched items from loader\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        start_true = batch['start_positions'].to(device)\n        end_true = batch['end_positions'].to(device)\n        # make predictions\n        outputs = model(input_ids, attention_mask=attention_mask)\n        # pull preds out\n        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n        # calculate accuracy for both and append to accuracy list\n        acc.append(((start_pred == start_true).sum()/len(start_pred)).item())\n        acc.append(((end_pred == end_true).sum()/len(end_pred)).item())\n# calculate average accuracy in total\nacc = sum(acc)/len(acc)\nacc","metadata":{"execution":{"iopub.status.busy":"2023-10-30T05:57:43.911121Z","iopub.execute_input":"2023-10-30T05:57:43.911717Z","iopub.status.idle":"2023-10-30T06:00:49.333851Z","shell.execute_reply.started":"2023-10-30T05:57:43.911684Z","shell.execute_reply":"2023-10-30T06:00:49.332873Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stderr","text":"100%|██████████| 1269/1269 [03:05<00:00,  6.84it/s]\n","output_type":"stream"},{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"0.6691046099408204"},"metadata":{}}]},{"cell_type":"code","source":"print(\"T/F\\tstart\\tend\\n\")\nfor i in range(len(start_true)):\n    print(f\"true\\t{start_true[i]}\\t{end_true[i]}\\n\"\n          f\"pred\\t{start_pred[i]}\\t{end_pred[i]}\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-10-30T06:01:30.622028Z","iopub.execute_input":"2023-10-30T06:01:30.622400Z","iopub.status.idle":"2023-10-30T06:01:30.629903Z","shell.execute_reply.started":"2023-10-30T06:01:30.622369Z","shell.execute_reply":"2023-10-30T06:01:30.629123Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"T/F\tstart\tend\n\ntrue\t67\t68\npred\t67\t68\n\ntrue\t67\t68\npred\t67\t68\n\ntrue\t67\t68\npred\t67\t68\n\ntrue\t66\t68\npred\t67\t68\n\ntrue\t171\t173\npred\t50\t65\n\ntrue\t171\t173\npred\t50\t65\n\ntrue\t171\t173\npred\t50\t65\n\ntrue\t171\t173\npred\t50\t65\n\ntrue\t171\t173\npred\t50\t65\n\ntrue\t158\t161\npred\t2\t4\n\ntrue\t158\t161\npred\t2\t4\n\ntrue\t158\t161\npred\t2\t4\n\ntrue\t158\t161\npred\t2\t4\n\ntrue\t158\t161\npred\t2\t4\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"---\n\n# Save and Load the model","metadata":{}},{"cell_type":"code","source":"#save and load model\ntorch.save(model,\"./finetunedmodel\")\nm = torch.load(\"/kaggle/working/finetunedmodel\", map_location=torch.device('cpu'))\nm.eval()","metadata":{"execution":{"iopub.status.busy":"2023-10-30T06:43:39.991352Z","iopub.execute_input":"2023-10-30T06:43:39.992261Z","iopub.status.idle":"2023-10-30T06:43:40.294866Z","shell.execute_reply.started":"2023-10-30T06:43:39.992227Z","shell.execute_reply":"2023-10-30T06:43:40.294021Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"markdown","source":"Here I give some examples to my model to see how well I trained it. I started with more easier examples and then I gave it more complex ones.\n\nFor extractive textual QA tasks, we usually adopt two evaluation metrics, which measure *exact match* and partially *overlapped scores* respectively.\n\n- **Exact Match:** measures whether the predicted answer exactly matches the ground-truth answers. If the exact matching occurs, then assigns 1.0, otherwise assigns 0.0.\n- **F1 Score:** computes the average word overlap between predicted and ground-truth answers, which can ensure both of precision and recall rate are optimized at the same time.","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModel, AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained('/kaggle/working/custom-distilbert')","metadata":{"execution":{"iopub.status.busy":"2023-10-30T06:37:18.034026Z","iopub.execute_input":"2023-10-30T06:37:18.034903Z","iopub.status.idle":"2023-10-30T06:37:18.069624Z","shell.execute_reply.started":"2023-10-30T06:37:18.034870Z","shell.execute_reply":"2023-10-30T06:37:18.068778Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"# Load the fine-tuned modeol\nmod = AutoModel.from_pretrained(\"/kaggle/working/custom-distilbert\")\nmod.eval()","metadata":{"execution":{"iopub.status.busy":"2023-10-30T06:38:13.326426Z","iopub.execute_input":"2023-10-30T06:38:13.327175Z","iopub.status.idle":"2023-10-30T06:38:14.101130Z","shell.execute_reply.started":"2023-10-30T06:38:13.327140Z","shell.execute_reply":"2023-10-30T06:38:14.100158Z"},"trusted":true},"execution_count":94,"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"DistilBertModel(\n  (embeddings): Embeddings(\n    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n    (position_embeddings): Embedding(512, 768)\n    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (transformer): Transformer(\n    (layer): ModuleList(\n      (0-5): 6 x TransformerBlock(\n        (attention): MultiHeadSelfAttention(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n        )\n        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        (ffn): FFN(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          (activation): GELUActivation()\n        )\n        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      )\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"import string\nimport re\nimport torch\n# from transformers import AutoModelForXXX, AutoTokenizer\n\ndef predict(context, query):\n    inputs = tokenizer.encode_plus(query, context, return_tensors='pt')\n#     model.to('cpu')\n    outputs = m(**inputs)\n    answer_start = torch.argmax(outputs[0])  # get the most likely beginning of the answer with the argmax of the score\n    answer_end = torch.argmax(outputs[1]) + 1\n\n    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n\n    return answer\n\ndef normalize_text(s):\n    def remove_articles(text):\n        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n        return re.sub(regex, \" \", text)\n\n    def white_space_fix(text):\n        return \" \".join(text.split())\n\n    def remove_punc(text):\n        exclude = set(string.punctuation)\n        return \"\".join(ch for ch in text if ch not in exclude)\n\n    def lower(text):\n        return text.lower()\n    \n    return white_space_fix(remove_articles(remove_punc(lower(s))))\n\ndef compute_exact_match(prediction, truth):\n    return int(normalize_text(prediction) == normalize_text(truth))\n\ndef compute_f1(prediction, truth):\n    pred_tokens = normalize_text(prediction).split()\n    truth_tokens = normalize_text(truth).split()\n\n    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n        return int(pred_tokens == truth_tokens)\n\n    common_tokens = set(pred_tokens) & set(truth_tokens)\n\n    if len(common_tokens) == 0:\n        return 0\n\n    precision = len(common_tokens) / len(pred_tokens)\n    recall = len(common_tokens) / len(truth_tokens)\n\n    return 2 * (precision * recall) / (precision + recall)\n\n# Assuming that 'model' and 'tokenizer' have been loaded and initialized earlier in the code.\n# You can call the 'predict' function and then use 'compute_exact_match' and 'compute_f1' to evaluate the predictions.\n","metadata":{"execution":{"iopub.status.busy":"2023-10-30T06:44:44.109093Z","iopub.execute_input":"2023-10-30T06:44:44.110164Z","iopub.status.idle":"2023-10-30T06:44:44.123259Z","shell.execute_reply.started":"2023-10-30T06:44:44.110122Z","shell.execute_reply":"2023-10-30T06:44:44.122212Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"def give_an_answer(context,query,answer):\n    prediction = predict(context,query)\n    em_score = compute_exact_match(prediction, answer)\n    f1_score = compute_f1(prediction, answer)\n\n    print(f\"Question: {query}\")\n    print(f\"Prediction: {prediction}\")\n    print(f\"True Answer: {answer}\")\n    print(f\"EM: {em_score}\")\n    print(f\"F1: {f1_score}\")\n    print(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-10-30T06:44:44.788274Z","iopub.execute_input":"2023-10-30T06:44:44.789005Z","iopub.status.idle":"2023-10-30T06:44:44.794325Z","shell.execute_reply.started":"2023-10-30T06:44:44.788975Z","shell.execute_reply":"2023-10-30T06:44:44.793418Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"context = \"Hi! My name is Alexa and I am 21 years old. I used to live in Peristeri of Athens, but now I moved on in Kaisariani of Athens.\"\n\nqueries = [\"How old is Alexa?\",\n           \"Where does Alexa live now?\",\n           \"Where Alexa used to live?\"\n          ]\nanswers = [\"21\",\n           \"Kaisariani of Athens\",\n           \"Peristeri of Athens\"\n          ]\n\nfor q,a in zip(queries,answers):\n    give_an_answer(context,q,a)","metadata":{"execution":{"iopub.status.busy":"2023-10-30T06:44:45.864200Z","iopub.execute_input":"2023-10-30T06:44:45.864594Z","iopub.status.idle":"2023-10-30T06:44:46.002090Z","shell.execute_reply.started":"2023-10-30T06:44:45.864562Z","shell.execute_reply":"2023-10-30T06:44:46.001080Z"},"trusted":true},"execution_count":108,"outputs":[{"name":"stdout","text":"Question: How old is Alexa?\nPrediction: 21 years old.\nTrue Answer: 21\nEM: 0\nF1: 0.5\n\n\nQuestion: Where does Alexa live now?\nPrediction: kaisariani of athens.\nTrue Answer: Kaisariani of Athens\nEM: 1\nF1: 1.0\n\n\nQuestion: Where Alexa used to live?\nPrediction: peristeri of athens,\nTrue Answer: Peristeri of Athens\nEM: 1\nF1: 1.0\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"context = \"\"\" Queen are a British rock band formed in London in 1970. Their classic line-up was Freddie Mercury (lead vocals, piano), \n            Brian May (guitar, vocals), Roger Taylor (drums, vocals) and John Deacon (bass). Their earliest works were influenced \n            by progressive rock, hard rock and heavy metal, but the band gradually ventured into more conventional and radio-friendly \n            works by incorporating further styles, such as arena rock and pop rock. \"\"\"\n\nqueries = [\"When did Queen found?\",\n           \"Who were the basic members of Queen band?\",\n           \"What kind of band they are?\"\n          ]\nanswers = [\"1970\",\n           \"Freddie Mercury, Brian May, Roger Taylor and John Deacon\",\n           \"rock\"\n          ]\n\nfor q,a in zip(queries,answers):\n    give_an_answer(context,q,a)","metadata":{"execution":{"iopub.status.busy":"2023-10-30T06:17:36.756614Z","iopub.execute_input":"2023-10-30T06:17:36.756966Z","iopub.status.idle":"2023-10-30T06:17:36.981226Z","shell.execute_reply.started":"2023-10-30T06:17:36.756940Z","shell.execute_reply":"2023-10-30T06:17:36.980289Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"Question: When did Queen found?\nPrediction: 1970.\nTrue Answer: 1970\nEM: 1\nF1: 1.0\n\n\nQuestion: Who were the basic members of Queen band?\nPrediction: freddie mercury ( lead vocals, piano ), brian may ( guitar, vocals ), roger taylor ( drums, vocals ) and john deacon ( bass ).\nTrue Answer: Freddie Mercury, Brian May, Roger Taylor and John Deacon\nEM: 0\nF1: 0.6923076923076924\n\n\nQuestion: What kind of band they are?\nPrediction: rock\nTrue Answer: rock\nEM: 1\nF1: 1.0\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"context = \"\"\" Mount Olympus is the highest mountain in Greece. It is part of the Olympus massif near \n              the Gulf of Thérmai of the Aegean Sea, located in the Olympus Range on the border between \n              Thessaly and Macedonia, between the regional units of Pieria and Larissa, about 80 km (50 mi) \n              southwest from Thessaloniki. Mount Olympus has 52 peaks and deep gorges. The highest peak, \n              Mytikas, meaning \"nose\", rises to 2917 metres (9,570 ft). It is one of the \n              highest peaks in Europe in terms of topographic prominence. \"\"\"\n\nqueries = [\n           \"How many metres is Olympus?\",\n           \"Where Olympus is near?\",\n           \"How far away is Olympus from Thessaloniki?\"\n          ]\nanswers = [\n           \"2917\",\n           \"Gulf of Thérmai of the Aegean Sea\",\n           \"80 km (50 mi)\"\n          ]\n\nfor q,a in zip(queries,answers):\n    give_an_answer(context,q,a)","metadata":{"execution":{"iopub.status.busy":"2023-10-30T06:17:42.106358Z","iopub.execute_input":"2023-10-30T06:17:42.107012Z","iopub.status.idle":"2023-10-30T06:17:42.370812Z","shell.execute_reply.started":"2023-10-30T06:17:42.106981Z","shell.execute_reply":"2023-10-30T06:17:42.369855Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"Question: How many metres is Olympus?\nPrediction: 2917\nTrue Answer: 2917\nEM: 1\nF1: 1.0\n\n\nQuestion: Where Olympus is near?\nPrediction: mount olympus\nTrue Answer: Gulf of Thérmai of the Aegean Sea\nEM: 0\nF1: 0\n\n\nQuestion: How far away is Olympus from Thessaloniki?\nPrediction: 80 km\nTrue Answer: 80 km (50 mi)\nEM: 0\nF1: 0.6666666666666666\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"context = \"\"\" The COVID-19 pandemic, also known as the coronavirus pandemic, is an ongoing pandemic of coronavirus disease 2019 (COVID-19) \n              caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). It was first identified in December 2019 in Wuhan, China. \n              The World Health Organization declared the outbreak a Public Health Emergency of International Concern in January 2020 and a pandemic \n              in March 2020. As of 6 February 2021, more than 105 million cases have been confirmed, with more than 2.3 million deaths attributed to COVID-19.\n              Symptoms of COVID-19 are highly variable, ranging from none to severe illness. The virus spreads mainly through the air when people are \n              near each other.[b] It leaves an infected person as they breathe, cough, sneeze, or speak and enters another person via their mouth, nose, or eyes. \n              It may also spread via contaminated surfaces. People remain infectious for up to two weeks, and can spread the virus even if they do not show symptoms.[9]\"\"\"\n\nqueries = [\n           \"What is COVID-19?\",\n           \"What is caused by COVID-19?\",\n           \"How many cases have been confirmed from COVID-19?\",\n           \"How many deaths have been confirmed from COVID-19?\",\n           \"How is COVID-19 spread?\",\n           \"How long can an infected person remain infected?\",\n           \"Can a infected person spread the virus even if they don't have symptoms?\",\n           \"What do elephants eat?\"\n          ]\nanswers = [\n           \"an ongoing pandemic of coronavirus disease 2019\",\n           \"severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)\",\n           \"more than 105 million cases\",\n           \"more than 2.3 million deaths\",\n           \"mainly through the air when people are near each other. It leaves an infected person as they breathe, cough, sneeze, or speak and enters another person via their mouth, nose, or eyes. It may also spread via contaminated surfaces.\",\n           \"up to two weeks\",\n           \"yes\",\n           \"\"\n          ]\n\nfor q,a in zip(queries,answers):\n    give_an_answer(context,q,a)","metadata":{"execution":{"iopub.status.busy":"2023-10-30T06:17:46.652370Z","iopub.execute_input":"2023-10-30T06:17:46.653047Z","iopub.status.idle":"2023-10-30T06:17:47.831388Z","shell.execute_reply.started":"2023-10-30T06:17:46.653016Z","shell.execute_reply":"2023-10-30T06:17:47.830435Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"Question: What is COVID-19?\nPrediction: \nTrue Answer: an ongoing pandemic of coronavirus disease 2019\nEM: 0\nF1: 0\n\n\nQuestion: What is caused by COVID-19?\nPrediction: coronavirus disease 2019 ( covid - 19 ) caused by severe acute respiratory syndrome coronavirus 2\nTrue Answer: severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)\nEM: 0\nF1: 0.6\n\n\nQuestion: How many cases have been confirmed from COVID-19?\nPrediction: more than 105 million\nTrue Answer: more than 105 million cases\nEM: 0\nF1: 0.888888888888889\n\n\nQuestion: How many deaths have been confirmed from COVID-19?\nPrediction: 2. 3 million\nTrue Answer: more than 2.3 million deaths\nEM: 0\nF1: 0.25\n\n\nQuestion: How is COVID-19 spread?\nPrediction: mainly through the air\nTrue Answer: mainly through the air when people are near each other. It leaves an infected person as they breathe, cough, sneeze, or speak and enters another person via their mouth, nose, or eyes. It may also spread via contaminated surfaces.\nEM: 0\nF1: 0.15\n\n\nQuestion: How long can an infected person remain infected?\nPrediction: up to two weeks,\nTrue Answer: up to two weeks\nEM: 1\nF1: 1.0\n\n\nQuestion: Can a infected person spread the virus even if they don't have symptoms?\nPrediction: people remain infectious for up to two weeks, and can spread the virus even if they do not show symptoms.\nTrue Answer: yes\nEM: 0\nF1: 0\n\n\nQuestion: What do elephants eat?\nPrediction: covid - 19 pandemic,\nTrue Answer: \nEM: 0\nF1: 0\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}