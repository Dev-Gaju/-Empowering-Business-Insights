{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Question Classification","metadata":{}},{"cell_type":"code","source":"import torch\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\nelse:\n    print('No GPU available')\n    device=torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2023-10-24T06:08:59.274062Z","iopub.execute_input":"2023-10-24T06:08:59.274363Z","iopub.status.idle":"2023-10-24T06:09:02.725808Z","shell.execute_reply.started":"2023-10-24T06:08:59.274339Z","shell.execute_reply":"2023-10-24T06:09:02.724871Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nquora= pd.read_csv(\"/kaggle/input/quora-insincere-questions-classification/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-10-24T06:09:02.728019Z","iopub.execute_input":"2023-10-24T06:09:02.728693Z","iopub.status.idle":"2023-10-24T06:09:07.779818Z","shell.execute_reply.started":"2023-10-24T06:09:02.728665Z","shell.execute_reply":"2023-10-24T06:09:07.778738Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"quora","metadata":{"execution":{"iopub.status.busy":"2023-10-24T06:09:07.781229Z","iopub.execute_input":"2023-10-24T06:09:07.781999Z","iopub.status.idle":"2023-10-24T06:09:07.804466Z","shell.execute_reply.started":"2023-10-24T06:09:07.781963Z","shell.execute_reply":"2023-10-24T06:09:07.803373Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                          qid  \\\n0        00002165364db923c7e6   \n1        000032939017120e6e44   \n2        0000412ca6e4628ce2cf   \n3        000042bf85aa498cd78e   \n4        0000455dfa3e01eae3af   \n...                       ...   \n1306117  ffffcc4e2331aaf1e41e   \n1306118  ffffd431801e5a2f4861   \n1306119  ffffd48fb36b63db010c   \n1306120  ffffec519fa37cf60c78   \n1306121  ffffed09fedb5088744a   \n\n                                             question_text  target  \n0        How did Quebec nationalists see their province...       0  \n1        Do you have an adopted dog, how would you enco...       0  \n2        Why does velocity affect time? Does velocity a...       0  \n3        How did Otto von Guericke used the Magdeburg h...       0  \n4        Can I convert montra helicon D to a mountain b...       0  \n...                                                    ...     ...  \n1306117  What other technical skills do you need as a c...       0  \n1306118  Does MS in ECE have good job prospects in USA ...       0  \n1306119                          Is foam insulation toxic?       0  \n1306120  How can one start a research project based on ...       0  \n1306121  Who wins in a battle between a Wolverine and a...       0  \n\n[1306122 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qid</th>\n      <th>question_text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00002165364db923c7e6</td>\n      <td>How did Quebec nationalists see their province...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000032939017120e6e44</td>\n      <td>Do you have an adopted dog, how would you enco...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0000412ca6e4628ce2cf</td>\n      <td>Why does velocity affect time? Does velocity a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000042bf85aa498cd78e</td>\n      <td>How did Otto von Guericke used the Magdeburg h...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0000455dfa3e01eae3af</td>\n      <td>Can I convert montra helicon D to a mountain b...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1306117</th>\n      <td>ffffcc4e2331aaf1e41e</td>\n      <td>What other technical skills do you need as a c...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1306118</th>\n      <td>ffffd431801e5a2f4861</td>\n      <td>Does MS in ECE have good job prospects in USA ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1306119</th>\n      <td>ffffd48fb36b63db010c</td>\n      <td>Is foam insulation toxic?</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1306120</th>\n      <td>ffffec519fa37cf60c78</td>\n      <td>How can one start a research project based on ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1306121</th>\n      <td>ffffed09fedb5088744a</td>\n      <td>Who wins in a battle between a Wolverine and a...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1306122 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"quora.loc[quora.target == 0].sample(5)[['question_text', 'target']]","metadata":{"execution":{"iopub.status.busy":"2023-10-24T06:09:07.807599Z","iopub.execute_input":"2023-10-24T06:09:07.808664Z","iopub.status.idle":"2023-10-24T06:09:07.960198Z","shell.execute_reply.started":"2023-10-24T06:09:07.808625Z","shell.execute_reply":"2023-10-24T06:09:07.959226Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                             question_text  target\n366923   What is the purpose of life and why are we cre...       0\n415930   Can you gain lineage citizenship in Hungary th...       0\n607910       Which is your worst selfie with your friends?       0\n1289951  Why is the mainstream American media still dis...       0\n711983     How much money do I need when I go to Belgrade?       0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question_text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>366923</th>\n      <td>What is the purpose of life and why are we cre...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>415930</th>\n      <td>Can you gain lineage citizenship in Hungary th...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>607910</th>\n      <td>Which is your worst selfie with your friends?</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1289951</th>\n      <td>Why is the mainstream American media still dis...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>711983</th>\n      <td>How much money do I need when I go to Belgrade?</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"questions=quora.question_text.values\ntarget=quora.target.values","metadata":{"execution":{"iopub.status.busy":"2023-10-24T06:09:07.961480Z","iopub.execute_input":"2023-10-24T06:09:07.961855Z","iopub.status.idle":"2023-10-24T06:09:07.966761Z","shell.execute_reply.started":"2023-10-24T06:09:07.961820Z","shell.execute_reply":"2023-10-24T06:09:07.965824Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"len(questions)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T06:09:07.968107Z","iopub.execute_input":"2023-10-24T06:09:07.968426Z","iopub.status.idle":"2023-10-24T06:09:07.980752Z","shell.execute_reply.started":"2023-10-24T06:09:07.968396Z","shell.execute_reply":"2023-10-24T06:09:07.979781Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"1306122"},"metadata":{}}]},{"cell_type":"code","source":"#https://huggingface.co/bert-base-uncased\nfrom transformers import AutoTokenizer, BertTokenizer  #Use the 12-layer BERT model, with an uncased vocab,uncased means lowercase\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True) #gpt2, bert-base_uncased","metadata":{"execution":{"iopub.status.busy":"2023-10-24T06:09:07.983849Z","iopub.execute_input":"2023-10-24T06:09:07.984452Z","iopub.status.idle":"2023-10-24T06:09:13.599800Z","shell.execute_reply.started":"2023-10-24T06:09:07.984427Z","shell.execute_reply":"2023-10-24T06:09:13.598820Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de863a8d859a4196bf266f0697928f89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a95db22ce7f445e9cb4763865822ccc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6dd118d8eb7e4e9b874a21c623f3b6f6"}},"metadata":{}}]},{"cell_type":"code","source":"print(\"original\", questions[0])\nprint('tokenize', tokenizer.tokenize(questions[0]))\nprint(\"token Id\", tokenizer.convert_tokens_to_ids(tokenizer.tokenize(questions[0])))","metadata":{"execution":{"iopub.status.busy":"2023-10-24T06:09:13.601051Z","iopub.execute_input":"2023-10-24T06:09:13.601456Z","iopub.status.idle":"2023-10-24T06:09:13.609233Z","shell.execute_reply.started":"2023-10-24T06:09:13.601431Z","shell.execute_reply":"2023-10-24T06:09:13.608185Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"original How did Quebec nationalists see their province as a nation in the 1960s?\ntokenize ['how', 'did', 'quebec', 'nationalists', 'see', 'their', 'province', 'as', 'a', 'nation', 'in', 'the', '1960s', '?']\ntoken Id [2129, 2106, 5447, 17934, 2156, 2037, 2874, 2004, 1037, 3842, 1999, 1996, 4120, 1029]\n","output_type":"stream"}]},{"cell_type":"code","source":"input_ids =[]\nfor ques in questions:\n    encoded_ques =tokenizer.encode(ques, add_special_tokens=True) #max_length\n    input_ids.append(encoded_ques)\nprint('Original: ', questions[0])\nprint('Token IDs:', input_ids[0])","metadata":{"execution":{"iopub.status.busy":"2023-10-24T06:09:13.610569Z","iopub.execute_input":"2023-10-24T06:09:13.611001Z","iopub.status.idle":"2023-10-24T06:21:54.518630Z","shell.execute_reply.started":"2023-10-24T06:09:13.610969Z","shell.execute_reply":"2023-10-24T06:21:54.517569Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (618 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"name":"stdout","text":"Original:  How did Quebec nationalists see their province as a nation in the 1960s?\nToken IDs: [101, 2129, 2106, 5447, 17934, 2156, 2037, 2874, 2004, 1037, 3842, 1999, 1996, 4120, 1029, 102]\n","output_type":"stream"}]},{"cell_type":"code","source":"max([len(ques) for ques in input_ids])\nmin([len(ques) for ques in input_ids])","metadata":{"execution":{"iopub.status.busy":"2023-10-24T06:21:54.522225Z","iopub.execute_input":"2023-10-24T06:21:54.522489Z","iopub.status.idle":"2023-10-24T06:21:54.825967Z","shell.execute_reply.started":"2023-10-24T06:21:54.522466Z","shell.execute_reply":"2023-10-24T06:21:54.825051Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"3"},"metadata":{}}]},{"cell_type":"code","source":"#check how many sentence have greater than 170 token\ncount_lenth =0\nfor text in input_ids:\n    if len(text) >64:\n        count_lenth +=1\nprint(count_lenth)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T06:21:54.827290Z","iopub.execute_input":"2023-10-24T06:21:54.827705Z","iopub.status.idle":"2023-10-24T06:21:55.074801Z","shell.execute_reply.started":"2023-10-24T06:21:54.827672Z","shell.execute_reply":"2023-10-24T06:21:55.073829Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"1043\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\n#add padding and truncation on the dataset\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n# check id and pad token\n# tokenizer.pad_token_id,tokenizer.pad_token\nmax_length= 64\ninput_ids_wpad= pad_sequences(input_ids, maxlen=max_length, dtype='long', value=0, truncating='post', padding='post') #post means last, opposed mean first, padding val 0","metadata":{"execution":{"iopub.status.busy":"2023-10-24T06:21:55.075870Z","iopub.execute_input":"2023-10-24T06:21:55.076195Z","iopub.status.idle":"2023-10-24T06:22:07.467840Z","shell.execute_reply.started":"2023-10-24T06:21:55.076169Z","shell.execute_reply":"2023-10-24T06:22:07.466953Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"CPU times: user 8.78 s, sys: 927 ms, total: 9.71 s\nWall time: 12.4 s\n","output_type":"stream"}]},{"cell_type":"code","source":"## atention mask simplify with are actual token and which are padding, bert havenot 0 voca so if 0 then pad otherwise token\nattention_mask=[]\nfor ques in input_ids_wpad:\n    att_mask=[int(token_id>0) for token_id in ques]\n    attention_mask.append(att_mask)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T06:22:07.469369Z","iopub.execute_input":"2023-10-24T06:22:07.470606Z","iopub.status.idle":"2023-10-24T06:23:07.974420Z","shell.execute_reply.started":"2023-10-24T06:22:07.470570Z","shell.execute_reply":"2023-10-24T06:23:07.973622Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#split dataset,target and mask on train and valid\nfrom sklearn.model_selection import train_test_split\ntrain_inputs, validation_inputs, train_targets, validation_targets = train_test_split(input_ids_wpad, target, random_state=42, test_size=0.15)\ntrain_mask, validation_mask, _, _ = train_test_split(attention_mask, target, random_state=42, test_size=0.15)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T06:23:07.975550Z","iopub.execute_input":"2023-10-24T06:23:07.975852Z","iopub.status.idle":"2023-10-24T06:23:09.131008Z","shell.execute_reply.started":"2023-10-24T06:23:07.975826Z","shell.execute_reply":"2023-10-24T06:23:09.130154Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#convert into pytorch data\ntrain_inputs=torch.tensor(train_inputs)\nvalid_inputs=torch.tensor(validation_inputs)\n\ntrain_targets = torch.tensor(train_targets)\nvalid_targets = torch.tensor(validation_targets)\n\ntrain_mask = torch.tensor(train_mask)\nvalid_mask = torch.tensor(validation_mask)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T06:23:09.132314Z","iopub.execute_input":"2023-10-24T06:23:09.132689Z","iopub.status.idle":"2023-10-24T06:23:37.577026Z","shell.execute_reply.started":"2023-10-24T06:23:09.132657Z","shell.execute_reply":"2023-10-24T06:23:37.575969Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_inputs.shape,train_mask.shape, train_targets.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-24T06:23:37.578290Z","iopub.execute_input":"2023-10-24T06:23:37.578581Z","iopub.status.idle":"2023-10-24T06:23:37.585188Z","shell.execute_reply.started":"2023-10-24T06:23:37.578555Z","shell.execute_reply":"2023-10-24T06:23:37.584229Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"(torch.Size([1110203, 64]), torch.Size([1110203, 64]), torch.Size([1110203]))"},"metadata":{}}]},{"cell_type":"code","source":"## create batche from the dataset \nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nbatch_size=32\n\n#crete data for training set\ntrain_data = TensorDataset(train_inputs, train_mask, train_targets)\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size=batch_size)\n\n# crete data for validation\nvalid_data = TensorDataset(valid_inputs, valid_mask, valid_targets)\nvalid_sampler = RandomSampler(valid_data)\nvalid_dataloader = DataLoader(valid_data, sampler = valid_sampler, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T06:23:37.586324Z","iopub.execute_input":"2023-10-24T06:23:37.586596Z","iopub.status.idle":"2023-10-24T06:23:37.596728Z","shell.execute_reply.started":"2023-10-24T06:23:37.586574Z","shell.execute_reply":"2023-10-24T06:23:37.595858Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"## now train the model\n# Get all of the model's parameters as a list of tuples.https://www.kaggle.com/code/gazu468/all-about-bert-you-need-to-know?scriptVersionId=115965914&cellId=75\nfrom transformers import BertForSequenceClassification, BertConfig, AdamW\nmodel= BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels=2, output_attentions=False, output_hidden_states= False)\nmodel.cuda()","metadata":{"execution":{"iopub.status.busy":"2023-10-24T06:23:37.597898Z","iopub.execute_input":"2023-10-24T06:23:37.598236Z","iopub.status.idle":"2023-10-24T06:23:46.814155Z","shell.execute_reply.started":"2023-10-24T06:23:37.598205Z","shell.execute_reply":"2023-10-24T06:23:46.813215Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dfe2aa86cae446799299086ed894924"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"# set the optimizers\noptimizers = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\nepochs=1","metadata":{"execution":{"iopub.status.busy":"2023-10-24T06:23:46.815536Z","iopub.execute_input":"2023-10-24T06:23:46.815855Z","iopub.status.idle":"2023-10-24T06:23:46.825925Z","shell.execute_reply.started":"2023-10-24T06:23:46.815829Z","shell.execute_reply":"2023-10-24T06:23:46.824941Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"#seed all over to make reproducible\nimport random\nseed_val=42\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)","metadata":{"execution":{"iopub.status.busy":"2023-10-24T06:23:46.870216Z","iopub.execute_input":"2023-10-24T06:23:46.870465Z","iopub.status.idle":"2023-10-24T06:23:46.881565Z","shell.execute_reply.started":"2023-10-24T06:23:46.870443Z","shell.execute_reply":"2023-10-24T06:23:46.880753Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"%%time\n### train the model\nfrom tqdm import tqdm\nloss_values=[]\nfor epoch_i in range(0, epochs):\n    total_loss=0\n    model.train()\n    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n    for step, batch in enumerate(tqdm(train_dataloader,desc=\"Training\")):\n        b_input_ids=batch[0].to(device)\n        b_input_mask =batch[1].to(device)\n        b_targets=batch[2].to(device)\n        model.zero_grad()\n\n        outputs = model(b_input_mask,token_type_ids=None,\n                       attention_mask=b_input_mask,\n                       labels=b_targets)\n        loss=outputs[0]\n        total_loss +=loss.item()\n        loss.backward()\n    # Clip the norm of the gradients to 1.0.\n    # This is to help prevent the \"exploding gradients\" problem.\n    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n    optimizers.step()\n    avg_train_loss = total_loss / len(train_dataloader)  \n    loss_values.append(avg_train_loss)\n    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n    print(\"Running Validation\")\n                \nprint(\"\")\nprint(\"Training complete!\")","metadata":{"execution":{"iopub.status.busy":"2023-10-24T06:23:46.882687Z","iopub.execute_input":"2023-10-24T06:23:46.883032Z","iopub.status.idle":"2023-10-24T08:02:24.502759Z","shell.execute_reply.started":"2023-10-24T06:23:46.883001Z","shell.execute_reply":"2023-10-24T08:02:24.501813Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"======== Epoch 1 / 1 ========\n","output_type":"stream"},{"name":"stderr","text":"Training:  96%|█████████▌| 33316/34694 [1:34:41<03:55,  5.85it/s]IOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\nTraining: 100%|██████████| 34694/34694 [1:38:37<00:00,  5.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Average training loss: 0.40\nRunning Validation\n\nTraining complete!\nCPU times: user 1h 38min 34s, sys: 13.2 s, total: 1h 38min 47s\nWall time: 1h 38min 37s\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score\neval_accuracy = 0\nall_preds = []\nall_targets = []\n\n# Iterate through the validation data loader.\nfor batch in tqdm(valid_dataloader):\n    batch = tuple(t.to(device) for t in batch)\n    b_input_ids, b_input_mask, b_targets = batch\n    with torch.no_grad():\n        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n    logits = outputs[0].detach().cpu().numpy()\n    target_ids = b_targets.to('cpu').numpy()\n    \n    # Convert logits to predicted labels (assuming multiclass classification).\n    preds = np.argmax(logits, axis=1)\n    \n    # Accumulate the total accuracy.\n    eval_accuracy += accuracy_score(target_ids, preds)\n    \n    # Append predictions and true labels to lists.\n    all_preds.extend(preds)\n    all_targets.extend(target_ids)\n\n# Calculate accuracy and F1 score for the entire validation dataset.\nnb_eval_steps = len(valid_dataloader)\naccuracy = eval_accuracy / nb_eval_steps\nf1 = f1_score(all_targets, all_preds, average='weighted')  # Use 'weighted' for multiclass F1 score\n\nprint(\"Accuracy: {0:.2f}\".format(accuracy))\nprint(\"F1 Score: {0:.2f}\".format(f1))\n\nprint(\"\\nValidation complete!\")\n","metadata":{"execution":{"iopub.status.busy":"2023-10-24T08:05:10.149240Z","iopub.execute_input":"2023-10-24T08:05:10.150000Z","iopub.status.idle":"2023-10-24T08:11:04.770644Z","shell.execute_reply.started":"2023-10-24T08:05:10.149969Z","shell.execute_reply":"2023-10-24T08:11:04.769660Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"100%|██████████| 6123/6123 [05:54<00:00, 17.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.94\nF1 Score: 0.91\n\nValidation complete!\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), \"model.pth\")","metadata":{"execution":{"iopub.status.busy":"2023-10-24T08:17:44.281466Z","iopub.execute_input":"2023-10-24T08:17:44.282320Z","iopub.status.idle":"2023-10-24T08:17:45.040443Z","shell.execute_reply.started":"2023-10-24T08:17:44.282290Z","shell.execute_reply":"2023-10-24T08:17:45.039405Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}